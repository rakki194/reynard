/* tslint:disable */
/* eslint-disable */
/**
 * Reynard API
 * Secure API backend for Reynard applications
 *
 * The version of the OpenAPI document: 1.0.0
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from "../runtime";
/**
 * Request model for ReynardAssistant.
 * @export
 * @interface OllamaAssistantRequest
 */
export interface OllamaAssistantRequest {
  /**
   * User message
   * @type {string}
   * @memberof OllamaAssistantRequest
   */
  message: string;
  /**
   * Assistant type (reynard, codewolf)
   * @type {string}
   * @memberof OllamaAssistantRequest
   */
  assistantType?: string;
  /**
   * Ollama model to use
   * @type {string}
   * @memberof OllamaAssistantRequest
   */
  model?: string;
  /**
   * Sampling temperature
   * @type {number}
   * @memberof OllamaAssistantRequest
   */
  temperature?: number;
  /**
   * Maximum tokens to generate
   * @type {number}
   * @memberof OllamaAssistantRequest
   */
  maxTokens?: number;
  /**
   * Enable streaming response
   * @type {boolean}
   * @memberof OllamaAssistantRequest
   */
  stream?: boolean;
  /**
   *
   * @type {object}
   * @memberof OllamaAssistantRequest
   */
  context?: object | null;
  /**
   * Enable tool calling
   * @type {boolean}
   * @memberof OllamaAssistantRequest
   */
  toolsEnabled?: boolean;
}

/**
 * Check if a given object implements the OllamaAssistantRequest interface.
 */
export function instanceOfOllamaAssistantRequest(
  value: object,
): value is OllamaAssistantRequest {
  if (!("message" in value) || value["message"] === undefined) return false;
  return true;
}

export function OllamaAssistantRequestFromJSON(
  json: any,
): OllamaAssistantRequest {
  return OllamaAssistantRequestFromJSONTyped(json, false);
}

export function OllamaAssistantRequestFromJSONTyped(
  json: any,
  ignoreDiscriminator: boolean,
): OllamaAssistantRequest {
  if (json == null) {
    return json;
  }
  return {
    message: json["message"],
    assistantType:
      json["assistant_type"] == null ? undefined : json["assistant_type"],
    model: json["model"] == null ? undefined : json["model"],
    temperature: json["temperature"] == null ? undefined : json["temperature"],
    maxTokens: json["max_tokens"] == null ? undefined : json["max_tokens"],
    stream: json["stream"] == null ? undefined : json["stream"],
    context: json["context"] == null ? undefined : json["context"],
    toolsEnabled:
      json["tools_enabled"] == null ? undefined : json["tools_enabled"],
  };
}

export function OllamaAssistantRequestToJSON(
  json: any,
): OllamaAssistantRequest {
  return OllamaAssistantRequestToJSONTyped(json, false);
}

export function OllamaAssistantRequestToJSONTyped(
  value?: OllamaAssistantRequest | null,
  ignoreDiscriminator: boolean = false,
): any {
  if (value == null) {
    return value;
  }

  return {
    message: value["message"],
    assistant_type: value["assistantType"],
    model: value["model"],
    temperature: value["temperature"],
    max_tokens: value["maxTokens"],
    stream: value["stream"],
    context: value["context"],
    tools_enabled: value["toolsEnabled"],
  };
}
