<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Lazy Loading Quick Guide - Reynard Documentation Test</title>
  <link rel="stylesheet" href="../styles.css">
  <link rel="stylesheet" href="../highlight.css">
  <link rel="icon" href="/favicon.ico">
</head>
<body>
  <nav class="docs-nav">
    <div class="nav-brand"><a href="../index.html">Reynard Documentation Test</a></div>
    <div class="nav-links"><a href="../index.html">Home</a><a href="../api.html">API Reference</a></div>
  </nav>
  <main class="docs-main">
    <div class="docs-content">
      <h1>Lazy Loading Quick Guide</h1>
      <div class="markdown-content"><h1>Lazy Loading Quick Guide</h1>
<h2>What is Lazy Loading?</h2>
<p>Lazy loading is a technique that delays loading heavy packages until they&#39;re actually needed. Instead of importing everything at startup (which can take 5-10 seconds), packages are loaded on-demand when you first use them.</p>
<h2>The Problem</h2>
<p>Heavy Python packages like <code>torch</code>, <code>transformers</code>, and <code>tensorflow</code> take a long time to import:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># This makes your app startup slow</span>
<span class="hljs-keyword">import</span> torch  <span class="hljs-comment"># Takes ~5 seconds</span>
<span class="hljs-keyword">import</span> transformers  <span class="hljs-comment"># Takes ~1 second</span>
<span class="hljs-keyword">import</span> tensorflow  <span class="hljs-comment"># Takes ~3 seconds</span></code></pre><h2>The Solution</h2>
<p>The lazy loading system provides proxy objects that only load the real package when you first access it:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># This is fast - no packages are loaded yet</span>
<span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> torch, transformers, tensorflow

<span class="hljs-comment"># Only now does torch actually get loaded</span>
model = torch.nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)  <span class="hljs-comment"># First access triggers loading</span>

<span class="hljs-comment"># Only now does transformers get loaded</span>
model = transformers.AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)  <span class="hljs-comment"># First access triggers loading</span></code></pre><h2>How It Works</h2>
<h3>1. Proxy Objects</h3>
<p>The system creates proxy objects that look like the real packages:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># In app/utils/lazy_loader.py</span>
torch = LazyPackageExport(<span class="hljs-string">&quot;torch&quot;</span>)
transformers = LazyPackageExport(<span class="hljs-string">&quot;transformers&quot;</span>)</code></pre><h3>2. On-Demand Loading</h3>
<p>When you access any attribute of these proxies, they load the real package:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># This triggers the actual import</span>
_ = torch.__version__  <span class="hljs-comment"># Loads torch now</span>
_ = transformers.__version__  <span class="hljs-comment"># Loads transformers now</span></code></pre><h3>3. Caching</h3>
<p>Once loaded, the package stays in memory for future use:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># First access - loads torch</span>
model = torch.nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)

<span class="hljs-comment"># Second access - uses cached torch</span>
tensor = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])  <span class="hljs-comment"># No loading needed</span></code></pre><h2>Common Usage Patterns</h2>
<h3>Basic Package Access</h3>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> torch, transformers, sklearn

<span class="hljs-comment"># Use exactly like normal imports</span>
model = torch.nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)
tokenizer = transformers.AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)
pca = sklearn.decomposition.PCA(n_components=<span class="hljs-number">2</span>)</code></pre><h3>Torch Components</h3>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> torch, F, nn, checkpoint

<span class="hljs-comment"># F is torch.nn.functional</span>
output = F.relu(<span class="hljs-built_in">input</span>)

<span class="hljs-comment"># nn is torch.nn</span>
layer = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)

<span class="hljs-comment"># checkpoint is torch.utils.checkpoint</span>
saved_output = checkpoint.checkpoint(model, <span class="hljs-built_in">input</span>)</code></pre><h3>Image Processing with Plugins</h3>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> get_pil_image_with_plugins, check_image_plugin_support

Image = get_pil_image_with_plugins()

<span class="hljs-comment"># Check for modern image format support</span>
<span class="hljs-keyword">if</span> check_image_plugin_support(<span class="hljs-string">&quot;jxl&quot;</span>):
    img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;image.jxl&quot;</span>)  <span class="hljs-comment"># JPEG XL support</span>
<span class="hljs-keyword">elif</span> check_image_plugin_support(<span class="hljs-string">&quot;avif&quot;</span>):
    img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;image.avif&quot;</span>)  <span class="hljs-comment"># AVIF support</span>
<span class="hljs-keyword">else</span>:
    img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;image.jpg&quot;</span>)  <span class="hljs-comment"># Fallback to JPEG</span></code></pre><h2>What Packages Are Available?</h2>
<p>The system pre-registers these common packages:</p>
<h3>Core ML Packages</h3>
<ul>
<li><code>torch</code> - PyTorch</li>
<li><code>torchvision</code> - PyTorch vision models</li>
<li><code>transformers</code> - Hugging Face transformers</li>
<li><code>timm</code> - Image models</li>
<li><code>tensorflow</code> - TensorFlow</li>
<li><code>sklearn</code> - Scikit-learn</li>
<li><code>ultralytics</code> - YOLO models</li>
</ul>
<h3>Data Science</h3>
<ul>
<li><code>numpy</code> - Numerical computing</li>
<li><code>pandas</code> - Data manipulation</li>
<li><code>matplotlib</code> - Plotting</li>
<li><code>seaborn</code> - Statistical plotting</li>
<li><code>tslearn</code> - Time series learning</li>
</ul>
<h3>Image Processing</h3>
<ul>
<li><code>PIL</code> - Python Imaging Library</li>
<li><code>cv2</code> - OpenCV</li>
<li><code>pillow_jxl</code> - JPEG XL support</li>
<li><code>pillow_avif</code> - AVIF support</li>
</ul>
<h3>Utilities</h3>
<ul>
<li><code>safetensors</code> - Safe tensor serialization</li>
<li><code>einops</code> - Einstein operations</li>
<li><code>pygit2</code> - Git operations</li>
<li><code>watchfiles</code> - File watching</li>
<li><code>sqlalchemy</code> - Database ORM</li>
</ul>
<h2>Performance Benefits</h2>
<h3>Startup Time</h3>
<ul>
<li><strong>Before</strong>: 5-10 seconds to start the app</li>
<li><strong>After</strong>: 1-2 seconds to start the app</li>
</ul>
<h3>Load Times (examples)</h3>
<ul>
<li><code>torch</code>: 5.8 seconds (heaviest)</li>
<li><code>transformers</code>: 0.9 seconds</li>
<li><code>sklearn</code>: 1.5 seconds</li>
<li><code>numpy</code>: 0.0 seconds (very fast)</li>
</ul>
<h2>Background Loading</h2>
<p>The system can also load packages in the background during startup:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> initialize_lazy_loading

<span class="hljs-comment"># Initialize the system</span>
loader = initialize_lazy_loading()

<span class="hljs-comment"># Start background loading (optional)</span>
<span class="hljs-keyword">await</span> loader.start_background_loading()</code></pre><p>This loads packages with different priorities:</p>
<ul>
<li><strong>Priority 1</strong>: <code>torch</code>, <code>numpy</code>, <code>PIL</code> (load first)</li>
<li><strong>Priority 2</strong>: <code>transformers</code>, <code>torchvision</code> (load second)</li>
<li><strong>Priority 3</strong>: <code>tensorflow</code>, <code>sklearn</code> (load last)</li>
</ul>
<h2>Monitoring</h2>
<p>Check the status of lazy loading:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> get_lazy_loading_status

status = get_lazy_loading_status()
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loaded <span class="hljs-subst">{status[<span class="hljs-string">&#x27;progress&#x27;</span>][<span class="hljs-string">&#x27;loaded_packages&#x27;</span>]}</span> of <span class="hljs-subst">{status[<span class="hljs-string">&#x27;progress&#x27;</span>][<span class="hljs-string">&#x27;total_packages&#x27;</span>]}</span> packages&quot;</span>)</code></pre><p>Or via HTTP endpoint:</p>
<pre><code class="hljs language-bash">curl http://localhost:7000/api/debug/lazy-loading-status</code></pre><h2>Error Handling</h2>
<p>If a package isn&#39;t available, you&#39;ll get a clear error:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> nonexistent_package

<span class="hljs-keyword">try</span>:
    _ = nonexistent_package.some_attribute
<span class="hljs-keyword">except</span> ImportError <span class="hljs-keyword">as</span> e:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Package not available: <span class="hljs-subst">{e}</span>&quot;</span>)</code></pre><h2>Migration Guide</h2>
<p>To migrate existing code:</p>
<ol>
<li><p><strong>Find heavy imports</strong>:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># Old way</span>
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel</code></pre></li>
<li><p><strong>Replace with lazy imports</strong>:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># New way</span>
<span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> torch, F, transformers</code></pre></li>
<li><p><strong>Test thoroughly</strong> - the behavior should be identical</p>
</li>
</ol>
<h2>Common Mistakes</h2>
<h3>❌ Don&#39;t do this - Direct imports</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># This loads torch immediately</span>
<span class="hljs-keyword">import</span> torch
model = torch.nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)</code></pre><h3>✅ Do this instead - Lazy imports</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># This loads torch only when first accessed</span>
<span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> torch
model = torch.nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)  <span class="hljs-comment"># torch loads here</span></code></pre><h3>❌ Don&#39;t do this - Transformers imports</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># This loads transformers immediately</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)</code></pre><h3>✅ Do this instead - Lazy transformers</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># This loads transformers only when first accessed</span>
<span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> transformers
model = transformers.AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)  <span class="hljs-comment"># transformers loads here</span></code></pre><h2>Thread Safety</h2>
<p>The system is thread-safe - multiple threads can safely access the same package:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> threading
<span class="hljs-keyword">from</span> app.utils.lazy_loader <span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">def</span> <span class="hljs-title function_">worker</span>():
    _ = torch.__version__  <span class="hljs-comment"># Safe to call from multiple threads</span>

threads = [threading.Thread(target=worker) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]
<span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> threads:
    t.start()
<span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> threads:
    t.join()
<span class="hljs-comment"># torch is only loaded once, all threads get the same instance</span></code></pre><h2>Summary</h2>
<p>The lazy loading system makes your app start faster by:</p>
<ol>
<li><strong>Delaying imports</strong> until they&#39;re actually needed</li>
<li><strong>Providing proxy objects</strong> that look like real packages</li>
<li><strong>Loading on first access</strong> and caching for future use</li>
<li><strong>Supporting background loading</strong> for common packages</li>
<li><strong>Maintaining thread safety</strong> for concurrent access</li>
</ol>
<p>The key insight is that you use the lazy-loaded packages exactly like normal imports - the only difference is when they get loaded (on-demand vs. at startup).</p>
</div>
    </div>
  </main>
  <footer class="docs-footer"><p>&copy; 2024 Reynard Documentation Test. Built with ❤️ using SolidJS.</p></footer>
</body>
</html>