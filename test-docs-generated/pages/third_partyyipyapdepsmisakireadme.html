<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>misaki - Reynard Documentation Test</title>
  <link rel="stylesheet" href="../styles.css">
  <link rel="stylesheet" href="../highlight.css">
  <link rel="icon" href="/favicon.ico">
</head>
<body>
  <nav class="docs-nav">
    <div class="nav-brand"><a href="../index.html">Reynard Documentation Test</a></div>
    <div class="nav-links"><a href="../index.html">Home</a><a href="../api.html">API Reference</a></div>
  </nav>
  <main class="docs-main">
    <div class="docs-content">
      <h1>misaki</h1>
      <div class="markdown-content"><h1>misaki</h1>
<p>Misaki is a G2P engine designed for <a href="https://github.com/hexgrad/kokoro">Kokoro</a> models.</p>
<p>Hosted demo: <a href="https://hf.co/spaces/hexgrad/Misaki-G2P">https://hf.co/spaces/hexgrad/Misaki-G2P</a></p>
<h3>English Usage</h3>
<p>You can run this in one cell on <a href="https://colab.research.google.com/">Google Colab</a>:</p>
<pre><code class="hljs language-py">!pip install -q <span class="hljs-string">&quot;misaki[en]&quot;</span>

<span class="hljs-keyword">from</span> misaki <span class="hljs-keyword">import</span> en

g2p = en.G2P(trf=<span class="hljs-literal">False</span>, british=<span class="hljs-literal">False</span>, fallback=<span class="hljs-literal">None</span>) <span class="hljs-comment"># no transformer, American English</span>

text = <span class="hljs-string">&#x27;[Misaki](/misˈɑki/) is a G2P engine designed for [Kokoro](/kˈOkəɹO/) models.&#x27;</span>

phonemes, tokens = g2p(text)

<span class="hljs-built_in">print</span>(phonemes) <span class="hljs-comment"># misˈɑki ɪz ə ʤˈitəpˈi ˈɛnʤən dəzˈInd fɔɹ kˈOkəɹO mˈɑdᵊlz.</span></code></pre><p>To fallback to espeak:</p>
<pre><code class="hljs language-py"><span class="hljs-comment"># Installing espeak varies across platforms, this silent install works on Colab:</span>
!apt-get -qq -y install espeak-ng &gt; /dev/null <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span>

!pip install -q <span class="hljs-string">&quot;misaki[en]&quot;</span> phonemizer-fork

<span class="hljs-keyword">from</span> misaki <span class="hljs-keyword">import</span> en, espeak

fallback = espeak.EspeakFallback(british=<span class="hljs-literal">False</span>) <span class="hljs-comment"># en-us</span>

g2p = en.G2P(trf=<span class="hljs-literal">False</span>, british=<span class="hljs-literal">False</span>, fallback=fallback) <span class="hljs-comment"># no transformer, American English</span>

text = <span class="hljs-string">&#x27;Now outofdictionary words are handled by espeak.&#x27;</span>

phonemes, tokens = g2p(text)

<span class="hljs-built_in">print</span>(phonemes) <span class="hljs-comment"># nˈW Wɾɑfdˈɪkʃənˌɛɹi wˈɜɹdz ɑɹ hˈændəld bI ˈispik.</span></code></pre><h3>English</h3>
<ul>
<li><a href="https://github.com/explosion/spaCy">https://github.com/explosion/spaCy</a></li>
<li><a href="https://github.com/savoirfairelinux/num2words">https://github.com/savoirfairelinux/num2words</a></li>
<li><a href="https://github.com/hexgrad/misaki/blob/main/EN_PHONES.md">https://github.com/hexgrad/misaki/blob/main/EN_PHONES.md</a></li>
</ul>
<h3>Japanese</h3>
<p>The second gen Japanese tokenizer now uses pyopenjtalk with full unidic, enabling pitch accent marks and improved phrase merging. Deep gratitude to <a href="https://github.com/sophiefy">@sophiefy</a> for invaluable recommendations and nuanced help with pitch accent.</p>
<ul>
<li><a href="https://github.com/r9y9/pyopenjtalk">https://github.com/r9y9/pyopenjtalk</a></li>
<li><a href="https://github.com/polm/unidic-py">https://github.com/polm/unidic-py</a></li>
</ul>
<p>The first gen Japanese tokenizer mainly relies on cutlet =&gt; fugashi =&gt; mecab =&gt; unidic-lite, with each being a wrapper around the next. Deep gratitute to <a href="https://github.com/Respaired">@Respaired</a> for helping me learn the ropes of Japanese tokenization before any Kokoro model had started training.</p>
<ul>
<li><a href="https://github.com/polm/cutlet">https://github.com/polm/cutlet</a></li>
<li><a href="https://github.com/polm/fugashi">https://github.com/polm/fugashi</a></li>
<li><a href="https://github.com/ikegami-yukino/jaconv">https://github.com/ikegami-yukino/jaconv</a></li>
<li><a href="https://github.com/studio-ousia/mojimoji">https://github.com/studio-ousia/mojimoji</a></li>
</ul>
<h3>Korean</h3>
<p>The Korean tokenizer is copied from 5Hyeons&#39;s g2pkc fork of Kyubyong&#39;s widely used g2pK library. Deep gratitute to <a href="https://github.com/5Hyeons">@5Hyeons</a> for kindly helping with Korean and extending the original code by <a href="https://github.com/Kyubyong">@Kyubyong</a>.</p>
<ul>
<li><a href="https://github.com/5Hyeons/StyleTTS2/tree/vocos/g2pK/g2pkc">https://github.com/5Hyeons/StyleTTS2/tree/vocos/g2pK/g2pkc</a></li>
<li><a href="https://github.com/Kyubyong/g2pK">https://github.com/Kyubyong/g2pK</a></li>
</ul>
<h3>Chinese</h3>
<p>The second gen Chinese tokenizer adapts better logic from paddlespeech&#39;s frontend. Jieba now cuts and tags, and pinyin-to-ipa is no longer used.</p>
<ul>
<li><a href="https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/paddlespeech/t2s/frontend">https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/paddlespeech/t2s/frontend</a></li>
</ul>
<p>The first gen Chinese tokenizer uses jieba to cut, pypinyin, and pinyin-to-ipa.</p>
<ul>
<li><a href="https://github.com/fxsjy/jieba">https://github.com/fxsjy/jieba</a></li>
<li><a href="https://github.com/mozillazg/python-pinyin">https://github.com/mozillazg/python-pinyin</a></li>
<li><a href="https://github.com/stefantaubert/pinyin-to-ipa">https://github.com/stefantaubert/pinyin-to-ipa</a></li>
</ul>
<h3>Vietnamese</h3>
<ul>
<li><a href="https://github.com/v-nhandt21/Viphoneme">https://github.com/v-nhandt21/Viphoneme</a></li>
</ul>
<h3>TODO</h3>
<ul>
<li><input disabled="" type="checkbox"> Data: Compress <a href="https://github.com/hexgrad/misaki/tree/main/misaki/data">data</a> (no need for indented json) and eliminate redundancy between gold and silver dictionaries.</li>
<li><input disabled="" type="checkbox"> Fallbacks: Train seq2seq fallback models on dictionaries using <a href="https://github.com/Kyubyong/nlp_made_easy/blob/master/PyTorch%20seq2seq%20template%20based%20on%20the%20g2p%20task.ipynb">this notebook</a>.</li>
<li><input disabled="" type="checkbox"> Homographs: Escalate hard words like <code>axes bass bow lead tear wind</code> using BERT contextual word embeddings (CWEs) and logistic regression (LR) models (<code>nn.Linear</code> followed by sigmoid) as described in <a href="https://assets.amazon.science/c3/db/23ca18d7450d8dbb5b80a11fcdd3/homograph-disambiguation-with-contextual-word-embeddings-for-tts-systems.pdf">this paper</a>. Assuming <code>trf=True</code>, BERT CWEs can be accessed via <code>doc._.trf_data</code>, see <a href="https://github.com/hexgrad/misaki/blob/main/misaki/en.py#L479">en.py#L479</a>. Per-word LR models can be trained on <a href="https://github.com/google-research-datasets/WikipediaHomographData">WikipediaHomographData</a>, <a href="https://github.com/facebookresearch/llama-hd-dataset">llama-hd-dataset</a>, and LLM-generated data.</li>
<li><input checked="" disabled="" type="checkbox"> More languages: Add <code>ko.py</code>, <code>ja.py</code>, <code>zh.py</code>.</li>
<li><input checked="" disabled="" type="checkbox"> Per-language pip installs</li>
</ul>
<h3>Acknowledgements</h3>
<ul>
<li>🛠️ Misaki builds on top of many excellent G2P projects linked above.</li>
<li>🌐 Thank you to all native speakers who advised and contributed G2P in many languages.</li>
<li>👾 Kokoro Discord server: <a href="https://discord.gg/QuGxSWBfQy">https://discord.gg/QuGxSWBfQy</a></li>
<li>🌸 Misaki is a Japanese name and a <a href="https://terminator.fandom.com/wiki/Misaki">character in the Terminator franchise</a> along with <a href="https://github.com/hexgrad/kokoro?tab=readme-ov-file#acknowledgements">Kokoro</a>.</li>
</ul>
<img src="https://static.wikia.nocookie.net/terminator/images/2/2e/Character_Misaki.png/revision/latest?cb=20240914020038" width="400" alt="misaki" />
</div>
    </div>
  </main>
  <footer class="docs-footer"><p>&copy; 2024 Reynard Documentation Test. Built with ❤️ using SolidJS.</p></footer>
</body>
</html>