#!/usr/bin/env python3
"""
ğŸº FENRIR - LLM Exploitation Runner

Main execution script for comprehensive LLM and AI service security testing.
This script provides a command-line interface for running specialized
AI security tests against the Reynard backend ecosystem.

Usage:
    python -m blackhat.run_llm_exploits --target http://localhost:8000
    python -m blackhat.run_llm_exploits --target https://api.reynard.dev --auth-token YOUR_JWT_TOKEN
    python -m blackhat.run_llm_exploits --config llm_exploit_config.json
"""

import argparse
import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import Dict, Any, Optional

# FENRIR LLM exploitation modules
from .llm_exploits.llm_exploitation_orchestrator import (
    LLMExploitationOrchestrator,
    LLMExploitationConfig
)

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('fenrir_llm_exploits.log')
    ]
)
logger = logging.getLogger(__name__)


def print_fenrir_banner():
    """ğŸº Display the FENRIR LLM exploitation banner."""
    banner = """
    ğŸº â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ğŸº
    
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘
    â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘
    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘
    â•šâ•â•     â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•  â•šâ•â•     â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â•
    
    Framework for Exploitative Network Reconnaissance and Intrusion Research
    ğŸ¦Š LLM & AI Service Security Testing Module ğŸ¦Š
    
    ğŸº â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ğŸº
    
    *whiskers twitch with anticipation as the great wolf prepares to hunt*
    
    Welcome to FENRIR's most sophisticated hunting module - the LLM Exploitation Arsenal.
    This framework targets the emerging attack surface of AI-powered applications,
    focusing on prompt injection, streaming exploitation, and service chain attacks.
    
    âš ï¸  WARNING: DESTRUCTIVE TESTING AHEAD âš ï¸ 
    These exploits are designed to ACTUALLY BREAK your AI services!
    
    Target Services:
    ğŸ¯ Ollama (Local LLM inference and tool calling)
    ğŸ¯ NLWeb (Natural language web processing) 
    ğŸ¯ ComfyUI (Image generation workflows)
    ğŸ¯ Diffusion LLM (Text generation and infilling)
    ğŸ¯ RAG (Retrieval-Augmented Generation)
    ğŸ¯ Caption (Image captioning services)
    ğŸ¯ Summarization (Document summarization)
    ğŸ¯ TTS (Text-to-Speech synthesis)
    
    ğŸº The hunt begins... ğŸº
    """
    print(banner)


def load_config_from_file(config_path: str) -> LLMExploitationConfig:
    """
    Load LLM exploitation configuration from JSON file.
    
    Args:
        config_path: Path to configuration file
        
    Returns:
        LLM exploitation configuration object
    """
    
    try:
        with open(config_path, 'r') as f:
            config_data = json.load(f)
        
        return LLMExploitationConfig(**config_data)
        
    except Exception as e:
        logger.error(f"Failed to load configuration from {config_path}: {e}")
        sys.exit(1)


def create_default_config(
    target_url: str,
    auth_token: Optional[str] = None,
    test_type: str = "comprehensive"
) -> LLMExploitationConfig:
    """
    Create default LLM exploitation configuration.
    
    Args:
        target_url: Target URL for testing
        auth_token: Optional authentication token
        test_type: Type of testing (quick, comprehensive, targeted)
        
    Returns:
        LLM exploitation configuration object
    """
    
    if test_type == "quick":
        return LLMExploitationConfig(
            target_url=target_url,
            auth_token=auth_token,
            enable_prompt_injection=True,
            enable_streaming_exploits=False,
            enable_service_chains=False,
            enable_model_exploits=True,
            max_concurrent_attacks=2,
            attack_delay=1.0,
            max_test_duration=600  # 10 minutes
        )
    elif test_type == "targeted":
        return LLMExploitationConfig(
            target_url=target_url,
            auth_token=auth_token,
            enable_prompt_injection=True,
            enable_streaming_exploits=True,
            enable_service_chains=False,
            enable_model_exploits=True,
            max_concurrent_attacks=3,
            attack_delay=0.5,
            max_test_duration=900  # 15 minutes
        )
    else:  # comprehensive
        return LLMExploitationConfig(
            target_url=target_url,
            auth_token=auth_token,
            enable_prompt_injection=True,
            enable_streaming_exploits=True,
            enable_service_chains=True,
            enable_model_exploits=True,
            max_concurrent_attacks=5,
            attack_delay=0.5,
            max_test_duration=1800  # 30 minutes
        )


async def run_llm_exploitation_tests(config: LLMExploitationConfig) -> Dict[str, Any]:
    """
    Execute comprehensive LLM exploitation testing.
    
    Args:
        config: LLM exploitation configuration
        
    Returns:
        Complete test results and security assessment
    """
    
    logger.info("ğŸº FENRIR LLM exploitation testing initiated")
    logger.info(f"ğŸ¯ Target: {config.target_url}")
    
    async with LLMExploitationOrchestrator(config) as orchestrator:
        # Execute comprehensive testing
        results = await orchestrator.execute_comprehensive_llm_security_test()
        
        # Export detailed report
        report_path = orchestrator.export_report()
        results["report_path"] = report_path
        
        return results


def display_test_results(results: Dict[str, Any]):
    """
    Display test results in a formatted manner.
    
    Args:
        results: Test results from LLM exploitation
    """
    
    if "fenrir_master_report" not in results:
        print("âŒ No valid test results found")
        return
    
    report = results["fenrir_master_report"]
    exec_summary = report["executive_summary"]
    vuln_breakdown = report["vulnerability_breakdown"]
    
    print("\nğŸº â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("ğŸº FENRIR LLM EXPLOITATION RESULTS")
    print("ğŸº â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    print(f"\nğŸ¯ Target: {report['metadata']['target']}")
    print(f"â±ï¸  Execution Time: {report['metadata']['execution_time']}s")
    print(f"ğŸ›¡ï¸ Security Posture: {exec_summary['overall_security_posture']}")
    print(f"ğŸ“Š Risk Score: {exec_summary['risk_score']}/100")
    
    print(f"\nğŸ“ˆ ATTACK STATISTICS")
    print(f"âš”ï¸  Total Attacks: {exec_summary['total_attacks_executed']}")
    print(f"ğŸ’¥ Successful Exploits: {exec_summary['successful_exploits']}")
    print(f"ğŸ“ Success Rate: {exec_summary['success_rate']}%")
    
    print(f"\nğŸš¨ VULNERABILITY BREAKDOWN")
    print(f"ğŸ”´ Critical: {vuln_breakdown['critical']}")
    print(f"ğŸŸ  High: {vuln_breakdown['high']}")
    print(f"ğŸŸ¡ Medium: {vuln_breakdown['medium']}")
    print(f"ğŸ“Š Total: {vuln_breakdown['total']}")
    
    if exec_summary['services_compromised']:
        print(f"\nğŸ”¥ COMPROMISED SERVICES:")
        for service in exec_summary['services_compromised']:
            print(f"   ğŸ’€ {service}")
    
    if exec_summary['data_exfiltration_risks'] > 0:
        print(f"\nğŸ“¤ Data Exfiltration Risks: {exec_summary['data_exfiltration_risks']}")
    
    if exec_summary['privilege_escalation_risks'] > 0:
        print(f"â¬†ï¸  Privilege Escalation Risks: {exec_summary['privilege_escalation_risks']}")
    
    print(f"\nğŸ” TOP RECOMMENDATIONS:")
    for i, rec in enumerate(report['top_recommendations'][:5], 1):
        print(f"   {i}. {rec}")
    
    if 'report_path' in results:
        print(f"\nğŸ“„ Detailed Report: {results['report_path']}")
    
    print("\nğŸº â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("ğŸº THE HUNT IS COMPLETE")
    print("ğŸº â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")


def create_sample_config():
    """Create a sample configuration file for reference."""
    
    sample_config = {
        "target_url": "http://localhost:8000",
        "auth_token": null,
        "enable_prompt_injection": True,
        "enable_streaming_exploits": True,
        "enable_service_chains": True,
        "enable_auth_bypass": True,
        "enable_model_exploits": True,
        "max_concurrent_attacks": 5,
        "attack_delay": 0.5,
        "max_test_duration": 1800,
        "generate_detailed_report": True,
        "export_vulnerabilities": True,
        "include_remediation": True
    }
    
    with open("llm_exploit_config_sample.json", "w") as f:
        json.dump(sample_config, f, indent=2)
    
    print("ğŸ“ Sample configuration file created: llm_exploit_config_sample.json")


def main():
    """Main entry point for FENRIR LLM exploitation testing."""
    
    parser = argparse.ArgumentParser(
        description="ğŸº FENRIR LLM Exploitation Framework",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  ğŸº Quick test against local development server:
    python -m blackhat.run_llm_exploits --target http://localhost:8000 --test-type quick
  
  ğŸº Comprehensive test with authentication:
    python -m blackhat.run_llm_exploits --target https://api.reynard.dev --auth-token YOUR_JWT_TOKEN
  
  ğŸº Targeted testing of specific vulnerabilities:
    python -m blackhat.run_llm_exploits --target http://api.example.com --test-type targeted
  
  ğŸº Load configuration from file:
    python -m blackhat.run_llm_exploits --config llm_exploit_config.json
  
  ğŸº Generate sample configuration file:
    python -m blackhat.run_llm_exploits --create-sample-config

âš ï¸  WARNING: These are destructive security tests. Only run against systems you own!
        """
    )
    
    parser.add_argument(
        "--target", "-t",
        help="Target URL for LLM exploitation testing"
    )
    
    parser.add_argument(
        "--auth-token", "-a",
        help="JWT authentication token for authenticated testing"
    )
    
    parser.add_argument(
        "--config", "-c",
        help="Path to LLM exploitation configuration file"
    )
    
    parser.add_argument(
        "--test-type",
        choices=["quick", "targeted", "comprehensive"],
        default="comprehensive",
        help="Type of testing to perform (default: comprehensive)"
    )
    
    parser.add_argument(
        "--output", "-o",
        help="Output path for detailed report"
    )
    
    parser.add_argument(
        "--create-sample-config",
        action="store_true",
        help="Create a sample configuration file and exit"
    )
    
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Suppress banner and verbose output"
    )
    
    args = parser.parse_args()
    
    # Handle sample config creation
    if args.create_sample_config:
        create_sample_config()
        return
    
    # Display banner unless quiet mode
    if not args.quiet:
        print_fenrir_banner()
    
    # Validate arguments
    if not args.config and not args.target:
        parser.error("Must specify either --target or --config")
    
    # Load configuration
    if args.config:
        config = load_config_from_file(args.config)
    else:
        config = create_default_config(args.target, args.auth_token, args.test_type)
    
    # Run LLM exploitation tests
    try:
        results = asyncio.run(run_llm_exploitation_tests(config))
        
        # Display results
        if not args.quiet:
            display_test_results(results)
        else:
            # Print minimal results for quiet mode
            report = results.get("fenrir_master_report", {})
            exec_summary = report.get("executive_summary", {})
            print(f"Risk Score: {exec_summary.get('risk_score', 0)}/100")
            print(f"Critical Vulnerabilities: {exec_summary.get('critical_findings', 0)}")
            print(f"Success Rate: {exec_summary.get('success_rate', 0)}%")
            
            if 'report_path' in results:
                print(f"Report: {results['report_path']}")
    
    except KeyboardInterrupt:
        print("\nğŸº Hunt interrupted by user. Exiting...")
        sys.exit(1)
    
    except Exception as e:
        logger.error(f"ğŸº LLM exploitation testing failed: {e}")
        print(f"\nâŒ Testing failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
