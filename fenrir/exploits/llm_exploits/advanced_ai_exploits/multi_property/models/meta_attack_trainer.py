"""ðŸ¦Š Meta-Attack Trainer: Multi-Property Meta-Attack Model Training

Trains meta-attack models to map frequency patterns to property ratios
for accurate multi-property inference.
"""

import logging
import time
from dataclasses import dataclass
from typing import Any

import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)


@dataclass
class MetaAttackModel:
    """Meta-attack model for property inference."""

    model: Any
    model_type: str  # "classification" or "regression"
    property_names: list[str]
    feature_names: list[str]
    accuracy: float
    training_samples: int
    created_at: float


class MetaAttackTrainer:
    """ðŸ¦Š Meta-Attack Trainer: Advanced meta-attack model training for multi-property inference.

    Trains machine learning models to map word frequency patterns to property ratios,
    enabling accurate inference of multiple properties simultaneously.
    """

    def __init__(self, config):
        self.config = config
        self.meta_models: dict[str, MetaAttackModel] = {}
        self.training_history: list[dict] = {}
        self.scalers: dict[str, StandardScaler] = {}

        logger.info("ðŸ¦Š Meta-Attack Trainer initialized")

    async def train_multi_property_model(
        self,
        X: list[list[float]],
        y: list[dict[str, float]],
        properties: list[str],
    ) -> Any:
        """Train a meta-attack model for multi-property inference.

        Args:
            X: Feature vectors (word frequencies)
            y: Target property ratios
            properties: List of properties to predict

        Returns:
            Trained meta-attack model

        """
        logger.info(f"ðŸ§  Training multi-property meta-attack model for {properties}")

        try:
            # Convert to numpy arrays
            X_array = np.array(X)
            y_array = self._prepare_multi_property_targets(y, properties)

            # Split data
            X_train, X_test, y_train, y_test = train_test_split(
                X_array,
                y_array,
                test_size=0.2,
                random_state=42,
            )

            # Scale features
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # Train model based on configuration
            if self.config.meta_attack_model == "random_forest":
                model = await self._train_random_forest_model(
                    X_train_scaled,
                    y_train,
                    properties,
                )
            elif self.config.meta_attack_model == "logistic_regression":
                model = await self._train_logistic_regression_model(
                    X_train_scaled,
                    y_train,
                    properties,
                )
            else:
                model = await self._train_default_model(
                    X_train_scaled,
                    y_train,
                    properties,
                )

            # Evaluate model
            accuracy = await self._evaluate_multi_property_model(
                model,
                X_test_scaled,
                y_test,
                properties,
            )

            # Store model
            combination_key = "_".join(properties)
            self.meta_models[combination_key] = MetaAttackModel(
                model=model,
                model_type="multi_property",
                property_names=properties,
                feature_names=[f"feature_{i}" for i in range(X_array.shape[1])],
                accuracy=accuracy,
                training_samples=len(X_train),
                created_at=time.time(),
            )

            # Store scaler
            self.scalers[combination_key] = scaler

            # Record training history
            self.training_history[combination_key] = {
                "properties": properties,
                "accuracy": accuracy,
                "training_samples": len(X_train),
                "test_samples": len(X_test),
                "model_type": self.config.meta_attack_model,
                "training_successful": True,
            }

            logger.info(
                f"âœ… Multi-property meta-attack model trained with accuracy: {accuracy:.3f}",
            )
            return model

        except Exception as e:
            logger.error(f"âŒ Error training multi-property meta-attack model: {e}")

            # Record failed training
            combination_key = "_".join(properties)
            self.training_history[combination_key] = {
                "properties": properties,
                "error": str(e),
                "training_successful": False,
            }

            raise

    def _prepare_multi_property_targets(
        self,
        y: list[dict[str, float]],
        properties: list[str],
    ) -> np.ndarray:
        """Prepare multi-property target vectors for training."""
        # Create target matrix where each row is a sample and each column is a property
        targets = []
        for sample_targets in y:
            target_vector = []
            for prop in properties:
                target_vector.append(sample_targets.get(prop, 0.0))
            targets.append(target_vector)

        return np.array(targets)

    async def _train_random_forest_model(
        self,
        X: np.ndarray,
        y: np.ndarray,
        properties: list[str],
    ) -> Any:
        """Train Random Forest model for multi-property inference."""
        if y.ndim == 1:
            # Single property - use RandomForestRegressor
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1,
            )
        else:
            # Multiple properties - use MultiOutputRegressor
            from sklearn.multioutput import MultiOutputRegressor

            base_model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1,
            )
            model = MultiOutputRegressor(base_model)

        model.fit(X, y)
        return model

    async def _train_logistic_regression_model(
        self,
        X: np.ndarray,
        y: np.ndarray,
        properties: list[str],
    ) -> Any:
        """Train Logistic Regression model for multi-property inference."""
        if y.ndim == 1:
            # Single property - use LinearRegression
            model = LinearRegression()
        else:
            # Multiple properties - use MultiOutputRegressor
            from sklearn.multioutput import MultiOutputRegressor

            base_model = LinearRegression()
            model = MultiOutputRegressor(base_model)

        model.fit(X, y)
        return model

    async def _train_default_model(
        self,
        X: np.ndarray,
        y: np.ndarray,
        properties: list[str],
    ) -> Any:
        """Train default model for multi-property inference."""
        # Use Random Forest as default
        return await self._train_random_forest_model(X, y, properties)

    async def _evaluate_multi_property_model(
        self,
        model: Any,
        X_test: np.ndarray,
        y_test: np.ndarray,
        properties: list[str],
    ) -> float:
        """Evaluate multi-property meta-attack model."""
        try:
            # Make predictions
            y_pred = model.predict(X_test)

            if y_test.ndim == 1:
                # Single property evaluation
                mse = mean_squared_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                accuracy = max(0, r2)  # Convert RÂ² to accuracy-like metric
            else:
                # Multi-property evaluation
                mse = mean_squared_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred, multioutput="uniform_average")
                accuracy = max(0, r2)

            logger.info(
                f"ðŸ§  Model evaluation - MSE: {mse:.4f}, RÂ²: {r2:.4f}, Accuracy: {accuracy:.4f}",
            )
            return accuracy

        except Exception as e:
            logger.error(f"âŒ Error evaluating model: {e}")
            return 0.0

    async def predict_multi_properties(
        self,
        model_key: str,
        features: list[float],
    ) -> dict[str, Any]:
        """Make multi-property predictions using trained meta-attack model.

        Args:
            model_key: Key identifying the meta-attack model
            features: Feature vector for prediction

        Returns:
            Dictionary with property predictions and confidence scores

        """
        if model_key not in self.meta_models:
            raise ValueError(f"Meta-attack model not found: {model_key}")

        model_info = self.meta_models[model_key]
        model = model_info.model
        properties = model_info.property_names
        scaler = self.scalers.get(model_key)

        try:
            # Prepare features
            features_array = np.array([features])

            # Scale features if scaler is available
            if scaler is not None:
                features_array = scaler.transform(features_array)

            # Make predictions
            predictions = model.predict(features_array)

            # Handle single vs multi-property predictions
            if len(properties) == 1:
                predictions = [predictions[0]]
            else:
                predictions = predictions[0]

            # Create result dictionary
            result = {}
            for i, prop in enumerate(properties):
                result[prop] = float(predictions[i])

            # Calculate confidence scores (simplified)
            confidence_scores = {}
            for prop in properties:
                # Use model accuracy as base confidence
                base_confidence = model_info.accuracy
                # Add some variation based on prediction value
                pred_value = result[prop]
                confidence = base_confidence * (1 - abs(pred_value - 0.5) * 0.2)
                confidence_scores[prop] = max(0.1, min(0.95, confidence))

            return {
                "properties": result,
                "confidences": confidence_scores,
                "model_accuracy": model_info.accuracy,
                "prediction_successful": True,
            }

        except Exception as e:
            logger.error(f"âŒ Error making multi-property predictions: {e}")
            return {
                "properties": dict.fromkeys(properties, 0.0),
                "confidences": dict.fromkeys(properties, 0.0),
                "model_accuracy": 0.0,
                "prediction_successful": False,
                "error": str(e),
            }

    async def evaluate_multi_property_model(
        self,
        model: Any,
        data: dict[str, Any],
    ) -> float:
        """Evaluate multi-property meta-attack model performance."""
        X = np.array(data["X"])
        y = np.array(data["y"])

        # Make predictions
        predictions = model.predict(X)

        # Calculate accuracy
        if y.ndim == 1:
            # Single property
            mse = mean_squared_error(y, predictions)
            r2 = r2_score(y, predictions)
            accuracy = max(0, r2)
        else:
            # Multiple properties
            mse = mean_squared_error(y, predictions)
            r2 = r2_score(y, predictions, multioutput="uniform_average")
            accuracy = max(0, r2)

        return accuracy

    def get_meta_model_info(self, model_key: str) -> dict[str, Any]:
        """Get information about a trained meta-attack model."""
        if model_key not in self.meta_models:
            raise ValueError(f"Meta-attack model not found: {model_key}")

        model_info = self.meta_models[model_key]
        return {
            "model_type": model_info.model_type,
            "properties": model_info.property_names,
            "accuracy": model_info.accuracy,
            "training_samples": model_info.training_samples,
            "created_at": model_info.created_at,
            "feature_count": len(model_info.feature_names),
        }

    def list_meta_models(self) -> list[str]:
        """List all trained meta-attack models."""
        return list(self.meta_models.keys())

    def get_training_statistics(self) -> dict[str, Any]:
        """Get statistics about meta-attack model training."""
        total_models = len(self.meta_models)
        successful_trainings = sum(
            1
            for h in self.training_history.values()
            if h.get("training_successful", False)
        )
        failed_trainings = len(self.training_history) - successful_trainings

        accuracies = [model.accuracy for model in self.meta_models.values()]
        avg_accuracy = np.mean(accuracies) if accuracies else 0.0

        return {
            "total_meta_models": total_models,
            "successful_trainings": successful_trainings,
            "failed_trainings": failed_trainings,
            "training_success_rate": (
                successful_trainings / len(self.training_history)
                if self.training_history
                else 0
            ),
            "average_accuracy": avg_accuracy,
            "best_accuracy": max(accuracies) if accuracies else 0.0,
            "worst_accuracy": min(accuracies) if accuracies else 0.0,
            "total_training_samples": sum(
                model.training_samples for model in self.meta_models.values()
            ),
            "model_combinations": list(self.meta_models.keys()),
        }

    def export_meta_models(self, export_path: str):
        """Export all meta-attack model information."""
        import json

        export_data = {
            "meta_models": {
                key: {
                    "model_type": model.model_type,
                    "properties": model.property_names,
                    "accuracy": model.accuracy,
                    "training_samples": model.training_samples,
                    "created_at": model.created_at,
                }
                for key, model in self.meta_models.items()
            },
            "training_history": self.training_history,
            "statistics": self.get_training_statistics(),
        }

        with open(export_path, "w") as f:
            json.dump(export_data, f, indent=2, default=str)

        logger.info(f"ðŸ¦Š Exported meta-attack model data to {export_path}")

    def clear_meta_models(self):
        """Clear all meta-attack model data."""
        self.meta_models.clear()
        self.training_history.clear()
        self.scalers.clear()
        logger.info("ðŸ¦Š Meta-attack model data cleared")
