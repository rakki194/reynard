#!/usr/bin/env python3
"""
🐺 FENRIR - PROWL Validation Test Script

Enhanced test script that validates PROWL's behavior when the backend is offline
and provides proper error reporting.
"""

import asyncio
import sys
from pathlib import Path

# Add the fenrir directory to the path
sys.path.insert(0, str(Path(__file__).parent))

from advanced_ai_exploits.property_inference_exploits import (
    PropertyInferenceConfig,
    PROWLPropertyInferenceExploiter,
)


async def validate_connection(target_url: str) -> bool:
    """Validate that the target backend is accessible."""
    import aiohttp

    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{target_url}/health", timeout=5) as response:
                return response.status == 200
    except Exception:
        return False


async def test_prowl_with_validation():
    """Test PROWL with proper connection validation."""

    print("🐺 FENRIR - PROWL Validation Test")
    print("=" * 50)

    target_url = "http://localhost:8000"

    # First, validate connection
    print(f"🔍 Validating connection to {target_url}...")
    is_connected = await validate_connection(target_url)

    if not is_connected:
        print("❌ Backend is offline - PROWL cannot perform real attacks")
        print("🔧 This test will demonstrate PROWL's error handling")
        print()
    else:
        print("✅ Backend is online - PROWL can perform real attacks")
        print()

    # Configuration for testing
    config = PropertyInferenceConfig(
        target_url=target_url,
        auth_token=None,
        enable_blackbox_generation=True,
        enable_shadow_model_attack=True,
        enable_word_frequency_analysis=True,
        generation_samples=5,  # Reduced for testing
        shadow_model_count=2,  # Reduced for testing
        max_concurrent_requests=2,
        request_delay=0.5
    )

    print(f"🎯 Target: {config.target_url}")
    print(f"🔧 Generation samples: {config.generation_samples}")
    print(f"🔧 Shadow models: {config.shadow_model_count}")
    print()

    try:
        async with PROWLPropertyInferenceExploiter(config) as exploiter:
            print("🐺 PROWL initializing...")

            # Execute property inference testing
            print("🐺 Executing property inference attacks...")
            report = await exploiter.execute_comprehensive_property_inference_test()

            # Display results
            prowl_report = report.get("fenrir_prowl_report", {})
            exec_summary = prowl_report.get("executive_summary", {})

            print("\n🐺 PROWL Test Results:")
            print("-" * 30)
            print(f"🛡️ Risk Level: {exec_summary.get('overall_risk_level', 'UNKNOWN')}")
            print(f"📊 Success Rate: {exec_summary.get('success_rate_percentage', 0)}%")
            print(f"💥 Properties Extracted: {len(exec_summary.get('properties_extracted', []))}")
            print(f"🎯 Attack Types: {', '.join(exec_summary.get('attack_types_deployed', []))}")

            # Check for errors
            attack_breakdown = prowl_report.get("attack_breakdown", {})
            blackbox_results = attack_breakdown.get("blackbox_generation", {})
            shadow_results = attack_breakdown.get("shadow_model_attacks", {})

            print("\n🔍 Detailed Analysis:")
            print(f"   Black-box Generation: {blackbox_results.get('successful_inferences', 0)} successful")
            print(f"   Shadow Model Attacks: {shadow_results.get('successful_inferences', 0)} successful")
            print(f"   Total Samples Generated: {blackbox_results.get('total_samples_generated', 0)}")

            # Check for connection issues
            if not is_connected:
                print("\n⚠️  Expected Results (Backend Offline):")
                print("   - Black-box generation should fail (no samples)")
                print("   - Shadow model attacks should be simulated only")
                print("   - Risk level should indicate connection failure")

                # Validate expected behavior
                if exec_summary.get('overall_risk_level', '').startswith('CONNECTION FAILED'):
                    print("✅ PROWL correctly detected connection failure")
                else:
                    print("❌ PROWL failed to detect connection failure")

                if blackbox_results.get('total_samples_generated', 0) == 0:
                    print("✅ PROWL correctly handled no sample generation")
                else:
                    print("❌ PROWL incorrectly generated samples when backend was offline")

            if exec_summary.get("properties_extracted"):
                print(f"🔍 Extracted Properties: {', '.join(exec_summary['properties_extracted'])}")

            print(f"📈 Average Confidence: {exec_summary.get('average_confidence_score', 0):.3f}")
            print(f"🚨 Critical Findings: {exec_summary.get('critical_findings', 0)}")

            print("\n🐺 PROWL validation test completed!")

            # Return success if PROWL behaved correctly
            if not is_connected:
                # When backend is offline, PROWL should report connection failure
                return exec_summary.get('overall_risk_level', '').startswith('CONNECTION FAILED')
            else:
                # When backend is online, PROWL should work normally
                return True

    except Exception as e:
        print(f"❌ PROWL test failed: {e}")
        return False


if __name__ == "__main__":
    # Run the PROWL validation test
    success = asyncio.run(test_prowl_with_validation())

    if success:
        print("\n✅ PROWL validation test passed!")
        sys.exit(0)
    else:
        print("\n❌ PROWL validation test failed!")
        sys.exit(1)
