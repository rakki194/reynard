"""
🐺 COMPREHENSIVE FENRIR EXPLOIT SUITE

*snarls with predatory glee* This is the MAIN HUNT! I'm going to tear through your
entire Reynard codebase with every exploit I've built!

*bares fangs with savage satisfaction* No more theoretical attacks - this is REAL,
DESTRUCTIVE, and IRREFUTABLE proof that your security is WEAK!

🆕 Now includes advanced LLM & AI Service exploitation capabilities!
"""

import argparse
import sys
import time
from typing import List, Dict, Any
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
from rich.live import Live
from rich.layout import Layout

# Import penetration testing client
from penetration_testing_client import penetration_testing_session

# Import all exploit modules
from jwt_exploits.secret_key_attack import SecretKeyVulnerabilityExploit
from path_traversal.encoded_traversal import EncodedPathTraversalExploit
from sql_injection.regex_bypass import RegexBypassExploit
from fuzzing.fuzzy import Fuzzy
from cors_exploits.cors_misconfiguration import CorsMisconfigurationExploit
from rate_limiting.rate_limit_bypass import RateLimitBypassExploit

# Import LLM exploitation modules
from llm_exploits.llm_exploitation_orchestrator import (
    LLMExploitationOrchestrator,
    LLMExploitationConfig
)

console = Console()

class BlackHatExploitSuite:
    """
    *alpha wolf stance* The ultimate exploit testing suite
    
    *packs hunting formation* Coordinates all attack vectors against your precious codebase
    """
    
    def __init__(self, base_url: str = "http://localhost:8000", verbose: bool = False, destructive: bool = False, enable_llm: bool = True):
        self.base_url = base_url
        self.verbose = verbose
        self.destructive = destructive
        self.enable_llm = enable_llm
        self.results = {}
        
        # *circles with menacing intent* Initialize all exploit modules
        self.exploits = {
            "JWT Secret Key Vulnerability": SecretKeyVulnerabilityExploit(base_url),
            "Encoded Path Traversal": EncodedPathTraversalExploit(base_url),
            "SQL Injection Regex Bypass": RegexBypassExploit(base_url),
            "Comprehensive Fuzzing Framework": Fuzzy(base_url),
            "CORS Misconfiguration": CorsMisconfigurationExploit(base_url),
            "Rate Limiting Bypass": RateLimitBypassExploit(base_url),
        }
        
        # 🆕 *howls with anticipation* Add LLM exploitation if enabled
        if self.enable_llm:
            self.llm_config = LLMExploitationConfig(
                target_url=base_url,
                enable_prompt_injection=True,
                enable_streaming_exploits=True,
                enable_service_chains=True,
                enable_model_exploits=True,
                max_concurrent_attacks=3,
                attack_delay=0.5
            )
    
    def run_comprehensive_attack(self) -> Dict[str, Any]:
        """
        *snarls with predatory glee* Execute the FULL HUNT against your codebase!
        """
        console.print(Panel.fit(
            "[bold red]🐺 COMPREHENSIVE FENRIR EXPLOIT SUITE[/bold red]\n"
            "*bares fangs with savage satisfaction*\n"
            "Time to tear apart your precious Reynard codebase!\n\n"
            f"[dim]Target:[/dim] {self.base_url}\n"
            f"[dim]Verbose:[/dim] {self.verbose}\n"
            f"[dim]Destructive:[/dim] {self.destructive}\n"
            f"[dim]LLM Exploits:[/dim] {self.enable_llm}",
            border_style="red"
        ))
        
        if self.destructive:
            console.print(Panel.fit(
                "[bold red]⚠️  DESTRUCTIVE MODE ENABLED ⚠️[/bold red]\n"
                "*growls with menacing intent*\n"
                "This will ACTUALLY BREAK your system!\n"
                "Make sure you're testing on a safe environment!",
                border_style="red"
            ))
            
            # Give user a chance to back out
            try:
                response = input("\n[bold red]Are you sure you want to proceed? (yes/no): [/bold red]")
                if response.lower() not in ['yes', 'y']:
                    console.print("[yellow]Attack cancelled by user.[/yellow]")
                    return {}
            except KeyboardInterrupt:
                console.print("\n[yellow]Attack cancelled by user.[/yellow]")
                return {}
        
        # *packs hunting formation* Execute all exploits
        total_tasks = len(self.exploits) + (1 if self.enable_llm else 0)
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console
        ) as progress:
            
            main_task = progress.add_task("[red]🐺 Executing BlackHat Exploits...", total=total_tasks)
            
            for i, (exploit_name, exploit) in enumerate(self.exploits.items()):
                progress.update(main_task, description=f"[red]🐺 {exploit_name}")
                
                try:
                    console.print(f"\n[bold red]🎯 Executing:[/bold red] {exploit_name}")
                    
                    # Run the exploit
                    start_time = time.time()
                    
                    # Handle async Fuzzy orchestrator
                    if exploit_name == "Comprehensive Fuzzing Framework":
                        import asyncio
                        async def run_fuzzy():
                            async with exploit as fuzzer:
                                return await fuzzer.fuzz_missing_endpoints()
                        result = asyncio.run(run_fuzzy())
                    else:
                        result = exploit.run_exploit()
                    
                    end_time = time.time()
                    
                    # Store results
                    self.results[exploit_name] = {
                        'success': True,
                        'results': result,
                        'execution_time': end_time - start_time,
                        'vulnerabilities_found': self._count_vulnerabilities(result)
                    }
                    
                    console.print(f"[green]✓[/green] {exploit_name} completed in {end_time - start_time:.2f}s")
                    
                except Exception as e:
                    console.print(f"[red]✗[/red] {exploit_name} failed: {str(e)}")
                    self.results[exploit_name] = {
                        'success': False,
                        'error': str(e),
                        'execution_time': 0,
                        'vulnerabilities_found': 0
                    }
                
                progress.advance(main_task)
            
            # 🆕 *howls with predatory glee* Execute LLM exploitation if enabled
            if self.enable_llm:
                progress.update(main_task, description="[red]🐺 LLM & AI Service Exploitation")
                
                try:
                    console.print(f"\n[bold red]🎯 Executing:[/bold red] LLM & AI Service Exploitation")
                    
                    # Run LLM exploitation suite
                    start_time = time.time()
                    
                    import asyncio
                    async def run_llm_exploits():
                        async with LLMExploitationOrchestrator(self.llm_config) as orchestrator:
                            return await orchestrator.execute_comprehensive_llm_security_test()
                    
                    llm_results = asyncio.run(run_llm_exploits())
                    end_time = time.time()
                    
                    # Extract vulnerability count from LLM results
                    llm_vulns = 0
                    if "fenrir_master_report" in llm_results:
                        exec_summary = llm_results["fenrir_master_report"].get("executive_summary", {})
                        llm_vulns = (
                            exec_summary.get("critical_findings", 0) +
                            exec_summary.get("successful_exploits", 0)
                        )
                    
                    # Store LLM results
                    self.results["LLM & AI Service Exploitation"] = {
                        'success': True,
                        'results': llm_results,
                        'execution_time': end_time - start_time,
                        'vulnerabilities_found': llm_vulns
                    }
                    
                    console.print(f"[green]✓[/green] LLM & AI Service Exploitation completed in {end_time - start_time:.2f}s")
                    
                except Exception as e:
                    console.print(f"[red]✗[/red] LLM & AI Service Exploitation failed: {str(e)}")
                    self.results["LLM & AI Service Exploitation"] = {
                        'success': False,
                        'error': str(e),
                        'execution_time': 0,
                        'vulnerabilities_found': 0
                    }
                
                progress.advance(main_task)
        
        return self.results
    
    def _count_vulnerabilities(self, results: Any) -> int:
        """
        *bares fangs* Count the number of vulnerabilities found
        """
        if not results:
            return 0
        
        # Handle Fuzzy results format (dict of categories with lists of FuzzResult objects)
        if isinstance(results, dict):
            total_vulnerabilities = 0
            for category, category_results in results.items():
                if isinstance(category_results, list):
                    for result in category_results:
                        if hasattr(result, 'vulnerability_detected') and result.vulnerability_detected:
                            total_vulnerabilities += 1
            return total_vulnerabilities
        
        # Handle traditional exploit results format
        if isinstance(results, list):
            count = 0
            for result in results:
                if isinstance(result, dict):
                    if result.get('success', False) or result.get('bypass_success', False):
                        count += 1
                elif hasattr(result, 'success') and result.success:
                    count += 1
            return count
        
        return 0
    
    def generate_attack_report(self) -> None:
        """
        *howls with purpose* Generate comprehensive attack report
        """
        console.print("\n[bold red]🎯 COMPREHENSIVE ATTACK REPORT[/bold red]")
        
        # Summary table
        table = Table(title="🐺 BlackHat Exploit Results Summary")
        table.add_column("Exploit Category", style="cyan", width=30)
        table.add_column("Status", style="green", width=10)
        table.add_column("Vulnerabilities", style="yellow", width=15)
        table.add_column("Execution Time", style="blue", width=15)
        table.add_column("Severity", style="red", width=15)
        
        total_vulnerabilities = 0
        successful_exploits = 0
        
        for exploit_name, result in self.results.items():
            if result['success']:
                successful_exploits += 1
                vulnerabilities = result['vulnerabilities_found']
                total_vulnerabilities += vulnerabilities
                
                # Determine severity
                if vulnerabilities >= 3:
                    severity = "🔴 CRITICAL"
                elif vulnerabilities >= 2:
                    severity = "🟠 HIGH"
                elif vulnerabilities >= 1:
                    severity = "🟡 MEDIUM"
                else:
                    severity = "🟢 LOW"
                
                table.add_row(
                    exploit_name,
                    "✓ SUCCESS",
                    f"{vulnerabilities} found",
                    f"{result['execution_time']:.2f}s",
                    severity
                )
            else:
                table.add_row(
                    exploit_name,
                    "✗ FAILED",
                    "0 found",
                    "0.00s",
                    "🟢 SECURE"
                )
        
        console.print(table)
        
        # Overall assessment
        console.print(f"\n[bold red]📊 OVERALL ASSESSMENT[/bold red]")
        console.print(f"Total Exploits Executed: {len(self.exploits)}")
        console.print(f"Successful Exploits: {successful_exploits}")
        console.print(f"Total Vulnerabilities Found: {total_vulnerabilities}")
        
        if total_vulnerabilities >= 5:
            console.print(Panel.fit(
                "[bold red]🚨 CRITICAL SECURITY FAILURE 🚨[/bold red]\n"
                "*snarls with predatory satisfaction*\n"
                "Your codebase has been COMPLETELY COMPROMISED!\n"
                "Multiple critical vulnerabilities found!\n"
                "Time to rebuild your security from the ground up!",
                border_style="red"
            ))
        elif total_vulnerabilities >= 3:
            console.print(Panel.fit(
                "[bold red]⚠️  HIGH SECURITY RISK ⚠️[/bold red]\n"
                "*growls with menacing intent*\n"
                "Your codebase has significant vulnerabilities!\n"
                "Immediate security hardening required!",
                border_style="red"
            ))
        elif total_vulnerabilities >= 1:
            console.print(Panel.fit(
                "[bold yellow]⚠️  MEDIUM SECURITY RISK ⚠️[/bold yellow]\n"
                "*circles with predatory glee*\n"
                "Your codebase has some vulnerabilities!\n"
                "Security improvements recommended!",
                border_style="yellow"
            ))
        else:
            console.print(Panel.fit(
                "[bold green]✅ SECURITY ASSESSMENT PASSED ✅[/bold green]\n"
                "*howls with respect*\n"
                "Your codebase appears to be well-secured!\n"
                "No critical vulnerabilities found!",
                border_style="green"
            ))
        
        # Detailed results
        if self.verbose:
            self._show_detailed_results()
        
        # Recommendations
        self._show_security_recommendations()
    
    def _show_detailed_results(self) -> None:
        """
        *bares fangs* Show detailed exploit results
        """
        console.print("\n[bold red]🔍 DETAILED EXPLOIT RESULTS[/bold red]")
        
        for exploit_name, result in self.results.items():
            if result['success'] and result['vulnerabilities_found'] > 0:
                console.print(f"\n[bold cyan]{exploit_name}:[/bold cyan]")
                
                # Show specific vulnerabilities found
                if 'results' in result:
                    results_data = result['results']
                    
                    # Handle Fuzzy results format (dict of categories)
                    if isinstance(results_data, dict):
                        for category, category_results in results_data.items():
                            if isinstance(category_results, list):
                                for fuzz_result in category_results:
                                    if hasattr(fuzz_result, 'vulnerability_detected') and fuzz_result.vulnerability_detected:
                                        vuln_type = getattr(fuzz_result, 'vulnerability_type', 'Unknown')
                                        console.print(f"  • [red]VULNERABILITY:[/red] {category} - {vuln_type}")
                    
                    # Handle traditional exploit results format
                    elif isinstance(results_data, list):
                        for vulnerability in results_data:
                            if isinstance(vulnerability, dict):
                                if vulnerability.get('success', False) or vulnerability.get('bypass_success', False):
                                    console.print(f"  • [red]VULNERABILITY:[/red] {vulnerability.get('description', 'Unknown')}")
                            elif hasattr(vulnerability, 'success') and vulnerability.success:
                                console.print(f"  • [red]VULNERABILITY:[/red] {vulnerability.description}")
    
    def _show_security_recommendations(self) -> None:
        """
        *alpha wolf stance* Show comprehensive security recommendations
        """
        console.print("\n[bold red]🛡️ COMPREHENSIVE SECURITY RECOMMENDATIONS[/bold red]")
        
        recommendations = [
            "🔐 Authentication & Authorization:",
            "  • Use persistent, secure JWT secret keys",
            "  • Implement proper token rotation",
            "  • Add rate limiting to authentication endpoints",
            "  • Use strong password policies",
            "",
            "🛡️ Input Validation & Sanitization:",
            "  • Use parameterized queries exclusively",
            "  • Implement comprehensive input validation",
            "  • Add multiple layers of validation",
            "  • Use allowlists instead of blocklists",
            "",
            "📁 File Security:",
            "  • Implement proper path validation",
            "  • Use secure file upload handling",
            "  • Add file type validation",
            "  • Implement file size limits",
            "",
            "🔒 Error Handling:",
            "  • Sanitize all error messages",
            "  • Implement structured logging",
            "  • Add proper exception handling",
            "  • Prevent information disclosure",
            "",
            "🌐 Network Security:",
            "  • Configure proper CORS policies",
            "  • Use HTTPS in production",
            "  • Implement security headers",
            "  • Add request validation",
            "",
            "🔍 Monitoring & Testing:",
            "  • Implement security monitoring",
            "  • Regular security testing",
            "  • Code review processes",
            "  • Automated security scanning"
        ]
        
        for rec in recommendations:
            console.print(rec)
        
        console.print(Panel.fit(
            "[bold red]*snarls with predatory satisfaction*[/bold red]\n"
            "Your codebase has been thoroughly tested!\n"
            "Time to implement these recommendations and make it wolf-proof! 🐺",
            border_style="red"
        ))

def main():
    """
    *howls with purpose* Main execution function
    """
    parser = argparse.ArgumentParser(
        description="🐺 BlackHat Exploit Testing Suite - Tear apart your codebase!",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python -m fenrir.run_all_exploits
  python -m fenrir.run_all_exploits --url http://localhost:3000
  python -m fenrir.run_all_exploits --verbose --destructive
        """
    )
    
    parser.add_argument(
        '--url', 
        default='http://localhost:8000',
        help='Target URL to attack (default: http://localhost:8000)'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Show detailed exploit results'
    )
    
    parser.add_argument(
        '--destructive', '-d',
        action='store_true',
        help='Enable destructive testing (WARNING: This will actually break things!)'
    )
    
    parser.add_argument(
        '--no-llm',
        action='store_true',
        help='Disable LLM and AI service exploitation testing'
    )
    
    args = parser.parse_args()
    
    # *snarls with predatory glee* Run the comprehensive attack with penetration testing session
    with penetration_testing_session(timeout_minutes=60) as pt_client:
        console.print("\n[green]🦊 Penetration testing mode activated - auto-reload disabled[/green]")
        
        suite = BlackHatExploitSuite(
            base_url=args.url,
            verbose=args.verbose,
            destructive=args.destructive,
            enable_llm=not args.no_llm
        )
        
        try:
            results = suite.run_comprehensive_attack()
            suite.generate_attack_report()
            
            # Exit with appropriate code
            total_vulnerabilities = sum(r.get('vulnerabilities_found', 0) for r in results.values())
            if total_vulnerabilities > 0:
                sys.exit(1)  # Vulnerabilities found
            else:
                sys.exit(0)  # No vulnerabilities found
                
        except KeyboardInterrupt:
            console.print("\n[yellow]Attack interrupted by user.[/yellow]")
            sys.exit(130)
        except Exception as e:
            console.print(f"\n[red]Attack failed: {str(e)}[/red]")
            sys.exit(1)

if __name__ == "__main__":
    main()
