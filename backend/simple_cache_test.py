#!/usr/bin/env python3
"""
Simple Cache Test Script
========================

A focused script to quickly prove that the caching system is working.
This script demonstrates cache hits, misses, and performance improvements.
"""

import asyncio
import time
from typing import Dict, Any

try:
    import requests
except ImportError:
    requests = None


async def test_search_service_cache() -> bool:
    """Test the search service cache directly."""
    print("ü¶ä Testing Search Service Cache")
    print("=" * 40)
    
    try:
        from app.api.search.service import OptimizedSearchService
        from app.api.search.models import SemanticSearchRequest
        
        # Initialize service
        service = OptimizedSearchService()
        await service.initialize()
        
        # Test query
        test_query = "authentication flow"
        request = SemanticSearchRequest(
            query=test_query,
            max_results=10,
            similarity_threshold=0.7
        )
        
        print(f"üîç Testing query: '{test_query}'")
        
        # First request (cache miss)
        print("\nüìù First request (should be cache miss):")
        start_time = time.time()
        result1 = await service.semantic_search(request)
        first_time = (time.time() - start_time) * 1000
        print(f"   Time: {first_time:.2f}ms")
        print(f"   Results: {len(result1.results) if result1.success else 0}")
        print(f"   Success: {result1.success}")
        
        # Second request (cache hit)
        print("\n‚ö° Second request (should be cache hit):")
        start_time = time.time()
        result2 = await service.semantic_search(request)
        second_time = (time.time() - start_time) * 1000
        print(f"   Time: {second_time:.2f}ms")
        print(f"   Results: {len(result2.results) if result2.success else 0}")
        print(f"   Success: {result2.success}")
        
        # Calculate speedup
        if first_time > 0 and second_time > 0:
            speedup = first_time / second_time
            print(f"\nüöÄ Performance Improvement:")
            print(f"   Speedup: {speedup:.1f}x faster")
            print(f"   Time saved: {first_time - second_time:.2f}ms")
        
        # Verify results are identical
        if result1.success and result2.success:
            if len(result1.results) == len(result2.results):
                print("   ‚úÖ Results are identical (cache working correctly)")
            else:
                print("   ‚ö†Ô∏è  Results differ (potential cache issue)")
        
        # Get metrics
        print(f"\nüìä Cache Metrics:")
        metrics = service.get_performance_metrics()
        search_metrics = metrics.get("search_metrics", {})
        print(f"   Total searches: {search_metrics.get('total_searches', 0)}")
        print(f"   Cache hits: {search_metrics.get('cache_hits', 0)}")
        print(f"   Cache misses: {search_metrics.get('cache_misses', 0)}")
        print(f"   Hit rate: {search_metrics.get('cache_hit_rate', 0):.1f}%")
        
        await service.close()
        return True
        
    except Exception as e:
        print(f"‚ùå Search service test failed: {e}")
        return False


def test_api_endpoint_cache() -> None:
    """Test API endpoint caching."""
    if requests is None:
        print("\n‚ö†Ô∏è  Requests library not available - skipping API endpoint tests")
        return
        
    print("\nüåê Testing API Endpoint Cache")
    print("=" * 40)
    
    base_url = "http://localhost:8000"
    
    # Test search endpoint
    test_queries = [
        "authentication",
        "database connection", 
        "error handling"
    ]
    
    for query in test_queries:
        print(f"\nüîç Testing query: '{query}'")
        
        try:
            # First request
            start_time = time.time()
            response1 = requests.get(
                f"{base_url}/api/search/semantic",
                params={"query": query, "max_results": 10},
                timeout=30
            )
            first_time = (time.time() - start_time) * 1000
            
            if response1.status_code == 200:
                print(f"   First request: {first_time:.2f}ms")
                
                # Second request
                start_time = time.time()
                response2 = requests.get(
                    f"{base_url}/api/search/semantic",
                    params={"query": query, "max_results": 10},
                    timeout=30
                )
                second_time = (time.time() - start_time) * 1000
                
                if response2.status_code == 200:
                    print(f"   Second request: {second_time:.2f}ms")
                    
                    # Calculate speedup
                    if first_time > 0 and second_time > 0:
                        speedup = first_time / second_time
                        print(f"   üöÄ Speedup: {speedup:.1f}x faster")
                    
                    # Verify responses are identical
                    if response1.json() == response2.json():
                        print("   ‚úÖ Responses are identical")
                    else:
                        print("   ‚ö†Ô∏è  Responses differ")
                else:
                    print(f"   ‚ùå Second request failed: {response2.status_code}")
            else:
                print(f"   ‚ùå First request failed: {response1.status_code}")
                
        except Exception as e:
            print(f"   ‚ùå API test failed: {e}")


def test_cache_metrics_endpoint() -> None:
    """Test the cache metrics endpoint."""
    if requests is None:
        print("\n‚ö†Ô∏è  Requests library not available - skipping metrics endpoint test")
        return
        
    print("\nüìä Testing Cache Metrics Endpoint")
    print("=" * 40)
    
    try:
        response = requests.get("http://localhost:8000/api/search/performance", timeout=10)
        
        if response.status_code == 200:
            metrics = response.json()
            print("‚úÖ Cache metrics retrieved successfully")
            
            search_metrics = metrics.get("metrics", {}).get("search_metrics", {})
            print(f"   Total searches: {search_metrics.get('total_searches', 0)}")
            print(f"   Cache hits: {search_metrics.get('cache_hits', 0)}")
            print(f"   Cache misses: {search_metrics.get('cache_misses', 0)}")
            print(f"   Hit rate: {search_metrics.get('cache_hit_rate', 0):.1f}%")
            print(f"   Average search time: {search_metrics.get('average_search_time_ms', 0):.2f}ms")
            
            cache_status = metrics.get("metrics", {}).get("cache_status", {})
            print(f"   Redis available: {cache_status.get('redis_available', False)}")
            print(f"   Legacy cache size: {cache_status.get('legacy_cache_size', 0)}")
            
        else:
            print(f"‚ùå Metrics endpoint failed: {response.status_code}")
            
    except Exception as e:
        print(f"‚ùå Metrics test failed: {e}")


def test_cache_clear_endpoint() -> None:
    """Test the cache clear endpoint."""
    if requests is None:
        print("\n‚ö†Ô∏è  Requests library not available - skipping cache clear test")
        return
        
    print("\nüßπ Testing Cache Clear Endpoint")
    print("=" * 40)
    
    try:
        response = requests.post("http://localhost:8000/api/search/cache/clear", timeout=10)
        
        if response.status_code == 200:
            result = response.json()
            print("‚úÖ Cache cleared successfully")
            print(f"   Message: {result.get('message', 'N/A')}")
        else:
            print(f"‚ùå Cache clear failed: {response.status_code}")
            
    except Exception as e:
        print(f"‚ùå Cache clear test failed: {e}")


async def main() -> None:
    """Main test function."""
    print("ü¶ä Simple Cache Proof Test")
    print("=" * 50)
    print("This script provides quick proof that the caching system is working.")
    print("=" * 50)
    
    # Test 1: Direct search service cache
    print("\n1Ô∏è‚É£ Testing Search Service Cache Directly")
    service_success = await test_search_service_cache()
    
    # Test 2: API endpoint cache
    print("\n2Ô∏è‚É£ Testing API Endpoint Cache")
    test_api_endpoint_cache()
    
    # Test 3: Cache metrics endpoint
    print("\n3Ô∏è‚É£ Testing Cache Metrics Endpoint")
    test_cache_metrics_endpoint()
    
    # Test 4: Cache clear endpoint
    print("\n4Ô∏è‚É£ Testing Cache Clear Endpoint")
    test_cache_clear_endpoint()
    
    # Summary
    print("\nüéâ Cache Proof Test Complete!")
    print("=" * 50)
    if service_success:
        print("‚úÖ Search service cache is working correctly")
    else:
        print("‚ùå Search service cache test failed")
    
    print("\nüìã To run more comprehensive tests:")
    print("   python cache_proof_demonstration.py")
    print("\nü¶ä The caching system provides significant performance improvements!")


if __name__ == "__main__":
    asyncio.run(main())
